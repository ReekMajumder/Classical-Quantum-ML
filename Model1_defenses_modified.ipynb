{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-python",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "blind-origin",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Pennylane\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "\n",
    "from advertorch.attacks import PGDAttack\n",
    "from advertorch.attacks import L2PGDAttack\n",
    "from advertorch.attacks import FABAttack\n",
    "from advertorch.attacks import SparseL1DescentAttack\n",
    "from advertorch.attacks import LinfSPSAAttack\n",
    "from advertorch.attacks import GradientSignAttack\n",
    "from advertorch.attacks import GradientAttack\n",
    "from advertorch.utils import predict_from_logits\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# OpenMP: number of parallel threads.\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "quality-independence",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 4                # Number of qubits\n",
    "step = 0.0004               # Learning rate\n",
    "batch_size = 4              # Number of samples for each training step\n",
    "num_epochs = 25              # Number of training epochs\n",
    "q_depth = 2                 # Depth of the quantum circuit (number of variational layers)\n",
    "gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = 0.01              # Initial spread of random quantum weights\n",
    "start_time = time.time()    # Start of the computation timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "driven-senator",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=n_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "opened-ballot",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "expanded-comparative",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    \"train\": transforms.Compose(\n",
    "        [\n",
    "            # transforms.RandomResizedCrop(224),     # uncomment for data augmentation\n",
    "            # transforms.RandomHorizontalFlip(),     # uncomment for data augmentation\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            # Normalize input channels using mean values and standard deviations of ImageNet.\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "    \"val\": transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "data_dir = \"data/dataset1\"\n",
    "# data_dir = \"data/hymenoptera_data\"\n",
    "image_datasets = {\n",
    "    x if x == \"train\" else \"validation\": datasets.ImageFolder(\n",
    "        os.path.join(data_dir, x), data_transforms[x]\n",
    "    )\n",
    "    for x in [\"train\", \"val\"]\n",
    "}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"validation\"]}\n",
    "class_names = image_datasets[\"train\"].classes\n",
    "\n",
    "# Initialize dataloader\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True)\n",
    "    for x in [\"train\", \"validation\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fresh-extreme",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_loss = 10000.0  # Large arbitrary number\n",
    "    best_acc_train = 0.0\n",
    "    best_loss_train = 10000.0  # Large arbitrary number\n",
    "    print(\"Training started:\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [\"train\", \"validation\"]:\n",
    "            if phase == \"train\":\n",
    "                # Set model to training mode\n",
    "                model.train()\n",
    "            else:\n",
    "                # Set model to evaluate mode\n",
    "                model.eval()\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            n_batches = dataset_sizes[phase] // batch_size\n",
    "            it = 0\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                since_batch = time.time()\n",
    "                batch_size_ = len(inputs)\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Track/compute gradient and make an optimization step only when training\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Print iteration results\n",
    "                running_loss += loss.item() * batch_size_\n",
    "                batch_corrects = torch.sum(preds == labels.data).item()\n",
    "                running_corrects += batch_corrects\n",
    "                print(\n",
    "                    \"Phase: {} Epoch: {}/{} Iter: {}/{} Batch time: {:.4f}\".format(\n",
    "                        phase,\n",
    "                        epoch + 1,\n",
    "                        num_epochs,\n",
    "                        it + 1,\n",
    "                        n_batches + 1,\n",
    "                        time.time() - since_batch,\n",
    "                    ),\n",
    "                    end=\"\\r\",\n",
    "                    flush=True,\n",
    "                )\n",
    "                it += 1\n",
    "\n",
    "            # Print epoch results\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "            print(\n",
    "                \"Phase: {} Epoch: {}/{} Loss: {:.4f} Acc: {:.4f}        \".format(\n",
    "                    \"train\" if phase == \"train\" else \"validation  \",\n",
    "                    epoch + 1,\n",
    "                    num_epochs,\n",
    "                    epoch_loss,\n",
    "                    epoch_acc,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Check if this is the best model wrt previous epochs\n",
    "            if phase == \"validation\" and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == \"validation\" and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "            if phase == \"train\" and epoch_acc > best_acc_train:\n",
    "                best_acc_train = epoch_acc\n",
    "            if phase == \"train\" and epoch_loss < best_loss_train:\n",
    "                best_loss_train = epoch_loss\n",
    "\n",
    "            # Update learning rate\n",
    "            if phase == \"train\":\n",
    "                scheduler.step()\n",
    "\n",
    "    # Print final results\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    time_elapsed = time.time() - since\n",
    "    print(\n",
    "        \"Training completed in {:.0f}m {:.0f}s\".format(time_elapsed // 60, time_elapsed % 60)\n",
    "    )\n",
    "    print(\"Best test loss: {:.4f} | Best test accuracy: {:.4f}\".format(best_loss, best_acc))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "framed-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model,adversary,defense):\n",
    "    since = time.time()\n",
    "    print(\"Validation started:\")\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    running_corrects =0\n",
    "    running_corrects_test=0\n",
    "    running_corrects_test_untargetted=0\n",
    "    running_corrects_test_cln=0\n",
    "    running_corrects_test_adv_defense=0\n",
    "\n",
    "    batch_corrects_test=0\n",
    "    batch_corrects_test_untargetted =0 \n",
    "    batch_corrects_test_clean_defend=0\n",
    "    batch_correts_adversarial_defense=0\n",
    "\n",
    "    # running_corrects_adversary_untargetted=0\n",
    "    # running_corrects_adversary_targetted=0\n",
    "\n",
    "    phase = \"validation\"\n",
    "\n",
    "    n_batches = dataset_sizes[phase]\n",
    "    it=0\n",
    "\n",
    "    for inputs,labels in dataloaders[phase]:\n",
    "        batch_size_ = len(inputs)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        adv_untargeted = adversary.perturb(inputs, labels)\n",
    "        adv_defended = defense(adv_untargeted)\n",
    "        cln_defended = defense(inputs)\n",
    "        \n",
    "        \n",
    "#         pred_adv = predict_from_logits(model(adv))\n",
    "        \n",
    "        \n",
    "        \n",
    "        pred_cln = predict_from_logits(model(inputs))\n",
    "        pred_untargeted_adv = predict_from_logits(model(adv_untargeted))\n",
    "        pred_cln_defended = predict_from_logits(model(cln_defended))\n",
    "        pred_adv_defended = predict_from_logits(model(adv_defended))\n",
    "        \n",
    "      # print(\"__________________\")\n",
    "      # print(\"original: \",pred_cln)\n",
    "      # print(\"untargetted Attack: \",pred_untargeted_adv)\n",
    "      # print(\"__________________\")\n",
    "      # outputs = model(inputs)\n",
    "      # _,preds = torch.max(outputs,1)\n",
    "        \n",
    "        # batch_corrects = torch.sum(preds == labels.data).item()\n",
    "        batch_corrects_test = torch.sum(pred_cln == labels.data).item()\n",
    "        batch_corrects_test_untargetted = torch.sum(pred_untargeted_adv == labels.data).item()\n",
    "        batch_corrects_test_clean_defend = torch.sum(pred_cln_defended == labels.data).item()\n",
    "        batch_correts_adversarial_defense = torch.sum(pred_adv_defended == labels.data).item()\n",
    "        \n",
    "        \n",
    "        # running_corrects += batch_corrects\n",
    "        running_corrects_test += batch_corrects_test\n",
    "        running_corrects_test_untargetted += batch_corrects_test_untargetted \n",
    "        running_corrects_test_cln += batch_corrects_test_clean_defend\n",
    "        running_corrects_test_adv_defense += batch_correts_adversarial_defense\n",
    "        \n",
    "    # final_acc = running_corrects / dataset_sizes[phase]\n",
    "    final_acc_test = running_corrects_test / dataset_sizes[phase]\n",
    "    final_acc_test_untargetted = running_corrects_test_untargetted / dataset_sizes[phase]\n",
    "    final_acc_test_cln = running_corrects_test_cln / dataset_sizes[phase]\n",
    "    final_acc_test_adv_def = running_corrects_test_adv_defense / dataset_sizes[phase]\n",
    "    \n",
    "    # print(\"Final Accuracy(original model): \",final_acc,final_acc_test)\n",
    "    time_elapsed = time.time() - since\n",
    "    print(\n",
    "        \"Testing completed in {:.0f}m {:.0f}s\".format(time_elapsed // 60, time_elapsed % 60)\n",
    "    )\n",
    "\n",
    "\n",
    "    print(\"Final Accuracy(original model): \",final_acc_test)\n",
    "    print(\"Adversarial Attack(untargetted) Accuracy: \",final_acc_test_untargetted)\n",
    "    print(\"Final Accuracy(original model+defense): \",final_acc_test_cln)\n",
    "    print(\"Adversarial Attack(untargetted+defense) Accuracy: \",final_acc_test_adv_def)\n",
    "    return final_acc_test,final_acc_test_untargetted,final_acc_test_cln,final_acc_test_adv_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "choice-ecuador",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassicalTransferLearningModel(nn.Module):\n",
    "    def __init__(self,num_of_features):\n",
    "        super().__init__()\n",
    "        # print(\"num of features\",num_of_features)\n",
    "        self.fc1 = nn.Linear(num_of_features,4)\n",
    "        self.fc2 = nn.Linear(4,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "several-wildlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classical = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "for param in model_classical.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = model_classical.fc.in_features\n",
    "model_classical.fc = ClassicalTransferLearningModel(num_ftrs)\n",
    "model_classical = model_classical.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "wrong-nurse",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_classical = nn.CrossEntropyLoss()\n",
    "optimizer_classical = optim.Adam(model_classical.fc.parameters(),lr=step)\n",
    "exp_lr_scheduler_classical = lr_scheduler.StepLR(\n",
    "    optimizer_classical, step_size=10, gamma=gamma_lr_scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "established-oasis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started:\n",
      "Phase: train Epoch: 1/25 Loss: 0.6783 Acc: 0.6319        \n",
      "Phase: validation   Epoch: 1/25 Loss: 0.6287 Acc: 0.5417        \n",
      "Phase: train Epoch: 2/25 Loss: 0.5451 Acc: 0.7418        \n",
      "Phase: validation   Epoch: 2/25 Loss: 0.5285 Acc: 0.7708        \n",
      "Phase: train Epoch: 3/25 Loss: 0.4591 Acc: 0.8407        \n",
      "Phase: validation   Epoch: 3/25 Loss: 0.4907 Acc: 0.8333        \n",
      "Phase: train Epoch: 4/25 Loss: 0.4319 Acc: 0.8462        \n",
      "Phase: validation   Epoch: 4/25 Loss: 0.4456 Acc: 0.8750        \n",
      "Phase: train Epoch: 5/25 Loss: 0.3914 Acc: 0.8516        \n",
      "Phase: validation   Epoch: 5/25 Loss: 0.4226 Acc: 0.8333        \n",
      "Phase: train Epoch: 6/25 Loss: 0.3342 Acc: 0.8901        \n",
      "Phase: validation   Epoch: 6/25 Loss: 0.4404 Acc: 0.8125        \n",
      "Phase: train Epoch: 7/25 Loss: 0.3098 Acc: 0.8901        \n",
      "Phase: validation   Epoch: 7/25 Loss: 0.4034 Acc: 0.8542        \n",
      "Phase: train Epoch: 8/25 Loss: 0.3856 Acc: 0.8242        \n",
      "Phase: validation   Epoch: 8/25 Loss: 0.3926 Acc: 0.8333        \n",
      "Phase: train Epoch: 9/25 Loss: 0.3117 Acc: 0.8516        \n",
      "Phase: validation   Epoch: 9/25 Loss: 0.3804 Acc: 0.8125        \n",
      "Phase: train Epoch: 10/25 Loss: 0.3340 Acc: 0.8571        \n",
      "Phase: validation   Epoch: 10/25 Loss: 0.3600 Acc: 0.8542        \n",
      "Phase: train Epoch: 11/25 Loss: 0.2889 Acc: 0.8956        \n",
      "Phase: validation   Epoch: 11/25 Loss: 0.3589 Acc: 0.9167        \n",
      "Phase: train Epoch: 12/25 Loss: 0.2539 Acc: 0.9286        \n",
      "Phase: validation   Epoch: 12/25 Loss: 0.3624 Acc: 0.8750        \n",
      "Phase: train Epoch: 13/25 Loss: 0.2468 Acc: 0.9341        \n",
      "Phase: validation   Epoch: 13/25 Loss: 0.3680 Acc: 0.8750        \n",
      "Phase: train Epoch: 14/25 Loss: 0.2205 Acc: 0.9231        \n",
      "Phase: validation   Epoch: 14/25 Loss: 0.3617 Acc: 0.8750        \n",
      "Phase: train Epoch: 15/25 Loss: 0.2619 Acc: 0.9121        \n",
      "Phase: validation   Epoch: 15/25 Loss: 0.3759 Acc: 0.8125        \n",
      "Phase: train Epoch: 16/25 Loss: 0.2156 Acc: 0.9451        \n",
      "Phase: validation   Epoch: 16/25 Loss: 0.3575 Acc: 0.8750        \n",
      "Phase: train Epoch: 17/25 Loss: 0.2624 Acc: 0.8901        \n",
      "Phase: validation   Epoch: 17/25 Loss: 0.3519 Acc: 0.8750        \n",
      "Phase: train Epoch: 18/25 Loss: 0.2854 Acc: 0.8846        \n",
      "Phase: validation   Epoch: 18/25 Loss: 0.3506 Acc: 0.8750        \n",
      "Phase: train Epoch: 19/25 Loss: 0.2305 Acc: 0.9176        \n",
      "Phase: validation   Epoch: 19/25 Loss: 0.3636 Acc: 0.8750        \n",
      "Phase: train Epoch: 20/25 Loss: 0.2537 Acc: 0.9011        \n",
      "Phase: validation   Epoch: 20/25 Loss: 0.3521 Acc: 0.8542        \n",
      "Phase: train Epoch: 21/25 Loss: 0.2283 Acc: 0.9286        \n",
      "Phase: validation   Epoch: 21/25 Loss: 0.3594 Acc: 0.9167        \n",
      "Phase: train Epoch: 22/25 Loss: 0.2373 Acc: 0.9121        \n",
      "Phase: validation   Epoch: 22/25 Loss: 0.3613 Acc: 0.8958        \n",
      "Phase: train Epoch: 23/25 Loss: 0.2561 Acc: 0.9231        \n",
      "Phase: validation   Epoch: 23/25 Loss: 0.3507 Acc: 0.8333        \n",
      "Phase: train Epoch: 24/25 Loss: 0.2494 Acc: 0.9121        \n",
      "Phase: validation   Epoch: 24/25 Loss: 0.3609 Acc: 0.9167        \n",
      "Phase: train Epoch: 25/25 Loss: 0.2241 Acc: 0.9341        \n",
      "Phase: validation   Epoch: 25/25 Loss: 0.3355 Acc: 0.9167        \n",
      "Training completed in 6m 35s\n",
      "Best test loss: 0.3355 | Best test accuracy: 0.9167\n"
     ]
    }
   ],
   "source": [
    "model_classical = train_model(model_classical,criterion_classical,optimizer_classical,exp_lr_scheduler_classical,num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dimensional-billy",
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary2_classical = PGDAttack(predict = model_classical,loss_fn = nn.CrossEntropyLoss(reduction=\"sum\"),\n",
    "                      eps=0.15,nb_iter=40,eps_iter=0.01,clip_min=0.0,clip_max=1.0,\n",
    "                      targeted =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "recovered-bridal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from advertorch.defenses import MedianSmoothing2D\n",
    "from advertorch.defenses import BitSqueezing\n",
    "from advertorch.defenses import JPEGFilter\n",
    "\n",
    "bit_squeezing = BitSqueezing(bit_depth = 5 )\n",
    "median_filter = MedianSmoothing2D(kernel_size = 3 )\n",
    "jpeg_filter = JPEGFilter(10)\n",
    "\n",
    "defense = nn.Sequential(jpeg_filter,bit_squeezing,median_filter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "plastic-hundred",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "suburban-google",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation started:\n",
      "Testing completed in 6m 0s\n",
      "Final Accuracy(original model):  0.9166666666666666\n",
      "Adversarial Attack(untargetted) Accuracy:  0.08333333333333333\n",
      "Final Accuracy(original model+defense):  0.6875\n",
      "Adversarial Attack(untargetted+defense) Accuracy:  0.8125\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output = test_model(model_classical,adversary2_classical,defense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-system",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-popularity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv_defended = defense(output[2])\n",
    "# # pred_adv_defended = predict_from_logits(model(adv_defended))\n",
    "# output2 = test_model(model_classical,adv_defended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "informational-enemy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def H_layer(nqubits):\n",
    "    \"\"\"Layer of single-qubit Hadamard gates.\n",
    "    \"\"\"\n",
    "    # print(\"hadamard\")\n",
    "    for idx in range(nqubits):\n",
    "        qml.Hadamard(wires=idx)\n",
    "\n",
    "\n",
    "def RY_layer(w):\n",
    "    \"\"\"Layer of parametrized qubit rotations around the y axis.\n",
    "    \"\"\"\n",
    "    # print(\"Ry\")\n",
    "    # print(w)\n",
    "    for idx, element in enumerate(w):\n",
    "        qml.RY(element, wires=idx)\n",
    "\n",
    "\n",
    "def entangling_layer(nqubits,flag=True):\n",
    "    \"\"\"Layer of CNOTs followed by another shifted layer of CNOT.\n",
    "    \"\"\"\n",
    "    # In other words it should apply something like :\n",
    "    # CNOT  CNOT  CNOT  CNOT...  CNOT\n",
    "    #   CNOT  CNOT  CNOT...  CNOT\n",
    "    # print(\"entangling\")\n",
    "    for i in range(0, nqubits - 1, 2):  # Loop over even indices: i=0,2,...N-2\n",
    "        qml.CNOT(wires=[i, i + 1])\n",
    "    for i in range(1, nqubits - 1, 2):  # Loop over odd indices:  i=1,3,...N-3\n",
    "        qml.CNOT(wires=[i, i + 1])\n",
    "\n",
    "    if flag == True:\n",
    "        qml.CNOT(wires=[n_qubits-1,0])\n",
    "    else:\n",
    "        qml.CNOT(wires=[0,n_qubits-1])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "adverse-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def quantum_net(q_input_features, q_weights_flat):\n",
    "    \"\"\"\n",
    "    The variational quantum circuit.\n",
    "    \"\"\"\n",
    "    # print(\"quantum_net: q_input_features ,q_weight_flat : \",type(q_input_features), \" , \",type(q_weights_flat))\n",
    "    # print(\"dimension\",q_input_features.ndim)\n",
    "    # Reshape weights\n",
    "    q_weights = q_weights_flat.reshape(q_depth, n_qubits)\n",
    "\n",
    "    \n",
    "    # Start from state |+> , unbiased w.r.t. |0> and |1>\n",
    "    H_layer(n_qubits)\n",
    "\n",
    "    # Embed features in the quantum node\n",
    "    RY_layer(q_input_features)\n",
    "\n",
    "    # Sequence of trainable variational layers\n",
    "    for k in range(q_depth):\n",
    "        entangling_layer(n_qubits)\n",
    "        RY_layer(q_weights[k])\n",
    "\n",
    "    entangling_layer(n_qubits,False)\n",
    "\n",
    "    # Expectation values in the Z basis\n",
    "    exp_vals = [qml.expval(qml.PauliZ(position)) for position in range(n_qubits)]\n",
    "    return tuple(exp_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "scenic-mechanics",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DressedQuantumNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Torch module implementing the *dressed* quantum net.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Definition of the *dressed* layout.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.pre_net = nn.Linear(512, n_qubits)\n",
    "        # print(\"DressedQNet_init_ n_qubit:\",n_qubits)\n",
    "        # print(\"DressedQNet_init_ q_delta:\",q_delta)\n",
    "        # print(\"DressedQNet_init_ q_depth:\",q_depth)\n",
    "        # print(q_delta * torch.randn(q_depth * n_qubits))\n",
    "        self.q_params = nn.Parameter(q_delta * torch.randn(q_depth * n_qubits))\n",
    "        # print(\"DressedQNet_init_ q_params:\",self.q_params)\n",
    "        self.post_net = nn.Linear(n_qubits, 2)\n",
    "\n",
    "    def forward(self, input_features):\n",
    "        \"\"\"\n",
    "        Defining how tensors are supposed to move through the *dressed* quantum\n",
    "        net.\n",
    "        \"\"\"\n",
    "        # print(\"DressedQNet_forward_ input\",input_features)\n",
    "        # print(\"input feature shape\",input_features.shape)\n",
    "        # obtain the input features for the quantum circuit\n",
    "        # by reducing the feature dimension from 512 to 4\n",
    "        pre_out = self.pre_net(input_features)\n",
    "        # print(\"DressedQNet_forward_ preout\",pre_out)\n",
    "        q_in = torch.tanh(pre_out) * np.pi / 2.0\n",
    "\n",
    "        # print(\"DressedQNet_forward_ q_in\",q_in)\n",
    "\n",
    "        # Apply the quantum circuit to each element of the batch and append to q_out\n",
    "        q_out = torch.Tensor(0, n_qubits)\n",
    "        # print(\"q_out: \",q_out)\n",
    "        q_out = q_out.to(device)\n",
    "        # print(q_in)\n",
    "        for elem in q_in:\n",
    "            q_out_elem = quantum_net(elem, self.q_params).float().unsqueeze(0)\n",
    "            # print(q_out_elem.draw())\n",
    "            q_out = torch.cat((q_out, q_out_elem))\n",
    "\n",
    "        # return the two-dimensional prediction from the postprocessing layer\n",
    "        return self.post_net(q_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "continuous-terminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hybrid = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "for param in model_hybrid.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "# Notice that model_hybrid.fc is the last layer of ResNet18\n",
    "model_hybrid.fc = DressedQuantumNet()\n",
    "\n",
    "# Use CUDA or CPU according to the \"device\" object.\n",
    "model_hybrid = model_hybrid.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "objective-titanium",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_hybrid = optim.Adam(model_hybrid.fc.parameters(), lr=step)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(\n",
    "    optimizer_hybrid, step_size=10, gamma=gamma_lr_scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "hundred-bench",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started:\n",
      "Phase: train Epoch: 1/25 Loss: 0.6300 Acc: 0.6703        \n",
      "Phase: validation   Epoch: 1/25 Loss: 0.6282 Acc: 0.6667        \n",
      "Phase: train Epoch: 2/25 Loss: 0.5153 Acc: 0.8132        \n",
      "Phase: validation   Epoch: 2/25 Loss: 0.5549 Acc: 0.6875        \n",
      "Phase: train Epoch: 3/25 Loss: 0.4700 Acc: 0.8132        \n",
      "Phase: validation   Epoch: 3/25 Loss: 0.5235 Acc: 0.6875        \n",
      "Phase: train Epoch: 4/25 Loss: 0.4024 Acc: 0.8846        \n",
      "Phase: validation   Epoch: 4/25 Loss: 0.4584 Acc: 0.7708        \n",
      "Phase: train Epoch: 5/25 Loss: 0.4507 Acc: 0.8297        \n",
      "Phase: validation   Epoch: 5/25 Loss: 0.4648 Acc: 0.7917        \n",
      "Phase: train Epoch: 6/25 Loss: 0.3568 Acc: 0.9066        \n",
      "Phase: validation   Epoch: 6/25 Loss: 0.4727 Acc: 0.7917        \n",
      "Phase: train Epoch: 7/25 Loss: 0.3215 Acc: 0.9066        \n",
      "Phase: validation   Epoch: 7/25 Loss: 0.4035 Acc: 0.8750        \n",
      "Phase: train Epoch: 8/25 Loss: 0.3415 Acc: 0.9121        \n",
      "Phase: validation   Epoch: 8/25 Loss: 0.4182 Acc: 0.8542        \n",
      "Phase: train Epoch: 9/25 Loss: 0.3621 Acc: 0.8516        \n",
      "Phase: validation   Epoch: 9/25 Loss: 0.4027 Acc: 0.8542        \n",
      "Phase: train Epoch: 10/25 Loss: 0.2964 Acc: 0.9341        \n",
      "Phase: validation   Epoch: 10/25 Loss: 0.3662 Acc: 0.8750        \n",
      "Phase: train Epoch: 11/25 Loss: 0.2869 Acc: 0.9176        \n",
      "Phase: validation   Epoch: 11/25 Loss: 0.3633 Acc: 0.9167        \n",
      "Phase: train Epoch: 12/25 Loss: 0.2977 Acc: 0.9231        \n",
      "Phase: validation   Epoch: 12/25 Loss: 0.3689 Acc: 0.8958        \n",
      "Phase: train Epoch: 13/25 Loss: 0.3210 Acc: 0.9121        \n",
      "Phase: validation   Epoch: 13/25 Loss: 0.3942 Acc: 0.7917        \n",
      "Phase: train Epoch: 14/25 Loss: 0.3203 Acc: 0.9066        \n",
      "Phase: validation   Epoch: 14/25 Loss: 0.3770 Acc: 0.8333        \n",
      "Phase: train Epoch: 15/25 Loss: 0.3142 Acc: 0.8901        \n",
      "Phase: validation   Epoch: 15/25 Loss: 0.3936 Acc: 0.8125        \n",
      "Phase: train Epoch: 16/25 Loss: 0.3453 Acc: 0.8791        \n",
      "Phase: validation   Epoch: 16/25 Loss: 0.3811 Acc: 0.8750        \n",
      "Phase: train Epoch: 17/25 Loss: 0.2804 Acc: 0.9176        \n",
      "Phase: validation   Epoch: 17/25 Loss: 0.3844 Acc: 0.8333        \n",
      "Phase: train Epoch: 18/25 Loss: 0.2225 Acc: 0.9670        \n",
      "Phase: validation   Epoch: 18/25 Loss: 0.3636 Acc: 0.9167        \n",
      "Phase: train Epoch: 19/25 Loss: 0.2699 Acc: 0.9396        \n",
      "Phase: validation   Epoch: 19/25 Loss: 0.3672 Acc: 0.8333        \n",
      "Phase: train Epoch: 20/25 Loss: 0.2321 Acc: 0.9670        \n",
      "Phase: validation   Epoch: 20/25 Loss: 0.3614 Acc: 0.9167        \n",
      "Phase: train Epoch: 21/25 Loss: 0.2762 Acc: 0.9286        \n",
      "Phase: validation   Epoch: 21/25 Loss: 0.4130 Acc: 0.7917        \n",
      "Phase: train Epoch: 22/25 Loss: 0.2573 Acc: 0.9560        \n",
      "Phase: validation   Epoch: 22/25 Loss: 0.3677 Acc: 0.8542        \n",
      "Phase: train Epoch: 23/25 Loss: 0.2808 Acc: 0.8901        \n",
      "Phase: validation   Epoch: 23/25 Loss: 0.3670 Acc: 0.8542        \n",
      "Phase: train Epoch: 24/25 Loss: 0.2321 Acc: 0.9560        \n",
      "Phase: validation   Epoch: 24/25 Loss: 0.3801 Acc: 0.8125        \n",
      "Phase: train Epoch: 25/25 Loss: 0.3302 Acc: 0.8736        \n",
      "Phase: validation   Epoch: 25/25 Loss: 0.3769 Acc: 0.8125        \n",
      "Training completed in 12m 20s\n",
      "Best test loss: 0.3614 | Best test accuracy: 0.9167\n"
     ]
    }
   ],
   "source": [
    "model_hybrid = train_model(\n",
    "    model_hybrid, criterion, optimizer_hybrid, exp_lr_scheduler, num_epochs=25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dynamic-samba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation started:\n",
      "Testing completed in 8m 22s\n",
      "Final Accuracy(original model):  0.9166666666666666\n",
      "Adversarial Attack(untargetted) Accuracy:  0.14583333333333334\n",
      "Final Accuracy(original model+defense):  0.6041666666666666\n",
      "Adversarial Attack(untargetted+defense) Accuracy:  0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "adversary2_hybrid_c1 = PGDAttack(predict = model_hybrid,loss_fn = nn.CrossEntropyLoss(reduction=\"sum\"),\n",
    "                      eps=0.15,nb_iter=40,eps_iter=0.01,clip_min=0.0,clip_max=1.0,\n",
    "                      targeted =False)\n",
    "output = test_model(model_hybrid,adversary2_hybrid_c1,defense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "sublime-pregnancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from advertorch.attacks import CarliniWagnerL2Attack\n",
    "\n",
    "adversary15 = CarliniWagnerL2Attack(predict= model_classical,\n",
    "#                                     loss_fn =  nn.CrossEntropyLoss(reduction=\"sum\"),\n",
    "                                    num_classes =2,confidence=0, learning_rate=0.01,\n",
    "                                    binary_search_steps=9, max_iterations=10000,\n",
    "                                    abort_early=True,initial_const=0.001,\n",
    "                                    targeted=False)\n",
    "\n",
    "adversary16 = CarliniWagnerL2Attack(predict= model_hybrid,\n",
    "#                                     loss_fn =  nn.CrossEntropyLoss(reduction=\"sum\"),\n",
    "                                    num_classes =2,confidence=0, learning_rate=0.01,\n",
    "                                    binary_search_steps=9, max_iterations=10000,\n",
    "                                    abort_early=True,initial_const=0.001,\n",
    "                                    targeted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "alternative-october",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classcical model\n",
      "Validation started:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-a70b1711c64d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"classcical model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0moutput_cnw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_classical\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0madversary15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdefense\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-33-ac8d4861541a>\u001b[0m in \u001b[0;36mtest_model\u001b[1;34m(model, adversary, defense)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0madv_untargeted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madversary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperturb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0madv_defended\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madv_untargeted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mcln_defended\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Reek\\anaconda3.0\\envs\\PENNYLANE_PYTORCH_advertorch2\\lib\\site-packages\\advertorch\\attacks\\carlini_wagner.py\u001b[0m in \u001b[0;36mperturb\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    229\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml2distsq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madv_img\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m                     self._forward_and_update_delta(\n\u001b[1;32m--> 231\u001b[1;33m                         optimizer, x_atanh, delta, y_onehot, loss_coeffs)\n\u001b[0m\u001b[0;32m    232\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabort_early\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mii\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iterations\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mNUM_CHECKS\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Reek\\anaconda3.0\\envs\\PENNYLANE_PYTORCH_advertorch2\\lib\\site-packages\\advertorch\\attacks\\carlini_wagner.py\u001b[0m in \u001b[0;36m_forward_and_update_delta\u001b[1;34m(self, optimizer, x_atanh, delta, y_onehot, loss_coeffs)\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[0madv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtanh_rescale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mx_atanh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mtransimgs_rescale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtanh_rescale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_atanh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m         \u001b[0ml2distsq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalc_l2distsq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransimgs_rescale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_onehot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml2distsq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_coeffs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Reek\\anaconda3.0\\envs\\PENNYLANE_PYTORCH_advertorch2\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Reek\\anaconda3.0\\envs\\PENNYLANE_PYTORCH_advertorch2\\lib\\site-packages\\torchvision\\models\\resnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Reek\\anaconda3.0\\envs\\PENNYLANE_PYTORCH_advertorch2\\lib\\site-packages\\torchvision\\models\\resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Reek\\anaconda3.0\\envs\\PENNYLANE_PYTORCH_advertorch2\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Reek\\anaconda3.0\\envs\\PENNYLANE_PYTORCH_advertorch2\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Reek\\anaconda3.0\\envs\\PENNYLANE_PYTORCH_advertorch2\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Reek\\anaconda3.0\\envs\\PENNYLANE_PYTORCH_advertorch2\\lib\\site-packages\\torchvision\\models\\resnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Reek\\anaconda3.0\\envs\\PENNYLANE_PYTORCH_advertorch2\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Reek\\anaconda3.0\\envs\\PENNYLANE_PYTORCH_advertorch2\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Reek\\anaconda3.0\\envs\\PENNYLANE_PYTORCH_advertorch2\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    395\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[1;32m--> 396\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"classcical model\")\n",
    "output_cnw = test_model(model_classical,adversary15,defense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-corruption",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hybrid model\")\n",
    "output_cnw = test_model(model_hybrid,adversary16,defense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-reset",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
